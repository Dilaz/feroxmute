# Model pricing per 1M tokens (USD)
# Format: [models.<provider>.<model-key>]

[models.anthropic]
# Claude 4.5 series
claude-4-5-sonnet = { input = 3.0, output = 15.0 }
claude-4-5-sonnet-thinking = { input = 3.0, output = 15.0 }
# Claude 4 series
claude-4-sonnet = { input = 3.0, output = 15.0 }
claude-4-sonnet-thinking = { input = 3.0, output = 15.0 }
claude-4-opus = { input = 15.0, output = 75.0 }
claude-4-opus-thinking = { input = 15.0, output = 75.0 }
claude-4-1-opus = { input = 15.0, output = 75.0 }
claude-4-1-opus-thinking = { input = 15.0, output = 75.0 }
# Claude 3.5 series
claude-3-5-haiku = { input = 0.8, output = 4.0 }
claude-3-5-sonnet = { input = 3.0, output = 15.0 }

[models.openai]
# GPT-4o series
gpt-4o = { input = 2.5, output = 10.0 }
gpt-4o-mini = { input = 0.15, output = 0.6 }
# GPT-4.1 series
gpt-4-1 = { input = 2.0, output = 8.0 }
gpt-4-1-mini = { input = 0.4, output = 1.6 }
gpt-4-1-nano = { input = 0.1, output = 0.4 }
# GPT-5 series
gpt-5 = { input = 1.25, output = 10.0 }
gpt-5-mini = { input = 0.25, output = 2.0 }
gpt-5-nano = { input = 0.05, output = 0.4 }
# O-series reasoning
o1 = { input = 15.0, output = 60.0 }
o1-mini = { input = 1.1, output = 4.4 }
o3 = { input = 2.0, output = 8.0 }
o3-mini = { input = 1.1, output = 4.4 }
o4-mini = { input = 1.1, output = 4.4 }

[models.gemini]
# Gemini 2.5 series
gemini-2-5-flash = { input = 0.3, output = 2.5 }
gemini-2-5-pro = { input = 1.25, output = 10.0 }
# Gemini 3 preview (placeholder - update when available)
gemini-3-pro-preview = { input = 1.5, output = 12.0 }
gemini-3-flash-preview = { input = 0.4, output = 3.0 }

[models.xai]
# Grok 4 series
grok-4 = { input = 3.0, output = 15.0 }
grok-4-fast = { input = 0.2, output = 0.5 }
grok-4-fast-reasoning = { input = 0.2, output = 0.5 }

[models.deepseek]
deepseek-v3 = { input = 0.5, output = 1.25 }
deepseek-r1 = { input = 0.8, output = 3.0 }

[models.cohere]
command-r-plus = { input = 2.5, output = 10.0 }
command-r = { input = 0.15, output = 0.6 }
command-a = { input = 2.5, output = 10.0 }

[models.perplexity]
sonar = { input = 1.0, output = 1.0 }
sonar-pro = { input = 3.0, output = 15.0 }
sonar-reasoning = { input = 1.0, output = 5.0 }

[models.ollama]
# Local models - no API cost
gemma = { input = 0.0, output = 0.0 }
gemma2 = { input = 0.0, output = 0.0 }
functiongemma = { input = 0.0, output = 0.0 }
llama3 = { input = 0.0, output = 0.0 }
"llama3.2" = { input = 0.0, output = 0.0 }
"llama3.3" = { input = 0.0, output = 0.0 }
mistral = { input = 0.0, output = 0.0 }
codellama = { input = 0.0, output = 0.0 }
qwen2 = { input = 0.0, output = 0.0 }
"qwen2.5" = { input = 0.0, output = 0.0 }
phi3 = { input = 0.0, output = 0.0 }
deepseek-coder = { input = 0.0, output = 0.0 }
